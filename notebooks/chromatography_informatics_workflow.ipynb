{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61429009",
   "metadata": {},
   "source": [
    "# Mass Spectrometry (MS) Data Analysis and Modeling\n",
    "\n",
    "This section demonstrates a complete mass spectrometry (MS) workflow, using synthetic mzML-like data to simulate Waters instrument outputs. The workflow includes:\n",
    "- Synthetic MS data generation (m/z, intensity, spectra)\n",
    "- Feature extraction (peak picking, centroiding, area)\n",
    "- Visualization (spectrum plots)\n",
    "- Machine learning modeling (classification/regression)\n",
    "- Discussion of relevance to Waters Informatics and the job description\n",
    "\n",
    "The approach mirrors real-world MS data analysis and is designed to showcase computational, modeling, and informatics skills for analytical instrumentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164e8f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters for synthetic MS data\n",
    "time_points = 20  # Number of spectra (scans)\n",
    "mz_min, mz_max = 50, 1000  # m/z range\n",
    "num_peaks = 5  # Number of peaks per spectrum\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic spectra\n",
    "data = []\n",
    "for scan in range(time_points):\n",
    "    rt = scan * 0.2  # Retention time in minutes\n",
    "    mz_peaks = np.random.uniform(mz_min, mz_max, num_peaks)\n",
    "    intensities = np.random.uniform(1e3, 1e5, num_peaks)\n",
    "    for mz, intensity in zip(mz_peaks, intensities):\n",
    "        data.append({'scan': scan, 'rt': rt, 'mz': mz, 'intensity': intensity})\n",
    "\n",
    "ms_df = pd.DataFrame(data)\n",
    "\n",
    "# Show a preview of the synthetic MS data\n",
    "ms_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a single MS spectrum (e.g., scan 0)\n",
    "scan_id = 0\n",
    "spectrum = ms_df[ms_df['scan'] == scan_id]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.stem(spectrum['mz'], spectrum['intensity'], basefmt=\" \")  # Removed use_line_collection\n",
    "plt.xlabel('m/z')\n",
    "plt.ylabel('Intensity')\n",
    "plt.title(f'Synthetic MS Spectrum (Scan {scan_id})')\n",
    "plt.show()\n",
    "\n",
    "# Simple peak picking: find the m/z with max intensity in each scan\n",
    "peak_picked = ms_df.loc[ms_df.groupby('scan')['intensity'].idxmax()]\n",
    "peak_picked = peak_picked[['scan', 'rt', 'mz', 'intensity']].reset_index(drop=True)\n",
    "\n",
    "# Simulate two sample types by shifting m/z peaks for half the scans\n",
    "type_labels = []\n",
    "for scan in range(time_points):\n",
    "    if scan < time_points // 2:\n",
    "        ms_df.loc[ms_df['scan'] == scan, 'mz'] += 5  # Type A: shift peaks\n",
    "        type_labels.append('A')\n",
    "    else:\n",
    "        type_labels.append('B')\n",
    "peak_picked['sample_type'] = type_labels\n",
    "\n",
    "# Feature: use the most intense m/z value per scan as input\n",
    "X = peak_picked[['mz']].values\n",
    "# Target: sample type\n",
    "y = peak_picked['sample_type'].values\n",
    "\n",
    "# Train/test split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf8217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Simulate two sample types by shifting m/z peaks for half the scans\n",
    "type_labels = []\n",
    "for scan in range(time_points):\n",
    "    if scan < time_points // 2:\n",
    "        ms_df.loc[ms_df['scan'] == scan, 'mz'] += 5  # Type A: shift peaks\n",
    "        type_labels.append('A')\n",
    "    else:\n",
    "        type_labels.append('B')\n",
    "peak_picked['sample_type'] = type_labels\n",
    "\n",
    "# Feature: use the most intense m/z value per scan as input\n",
    "X = peak_picked[['mz']].values\n",
    "# Target: sample type\n",
    "y = peak_picked['sample_type'].values\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc82e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Prepare feature matrix: use top N peaks per scan as features ---\n",
    "N = 3  # Number of peaks per scan to use as features\n",
    "features = []\n",
    "for scan in range(time_points):\n",
    "    scan_peaks = ms_df[ms_df['scan'] == scan].sort_values('intensity', ascending=False)\n",
    "    top_mz = scan_peaks['mz'].values[:N]\n",
    "    # Pad with zeros if fewer than N peaks\n",
    "    if len(top_mz) < N:\n",
    "        top_mz = np.pad(top_mz, (0, N - len(top_mz)), 'constant')\n",
    "    features.append(top_mz)\n",
    "features = np.array(features)\n",
    "\n",
    "# --- PCA ---\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(features)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "for label in np.unique(type_labels):\n",
    "    idx = np.array(type_labels) == label\n",
    "    plt.scatter(pca_result[idx, 0], pca_result[idx, 1], label=f'Sample {label}')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('PCA of MS Spectra (Top 3 Peaks)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Heatmap: Intensity vs. scan and m/z bins ---\n",
    "mz_bins = np.linspace(mz_min, mz_max, 50)\n",
    "scan_bins = np.arange(time_points + 1)\n",
    "heatmap, xedges, yedges = np.histogram2d(ms_df['scan'], ms_df['mz'], bins=[scan_bins, mz_bins], weights=ms_df['intensity'])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(heatmap.T, cmap='viridis', xticklabels=5, yticklabels=5)\n",
    "plt.xlabel('Scan')\n",
    "plt.ylabel('m/z bin')\n",
    "plt.title('MS Intensity Heatmap (Scan vs. m/z)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
